{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests, bs4, pandas as pd, time, sys\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = input(\"What job are you thinking?\")\n",
    "key_phrase = input(f'As a {key_word}, do you have any specific skills?')\n",
    "salary_in_thousand = int(input(\"How much are you trying to make?(Input is x $1000)\"))\n",
    "city = input(\"Where do you want to work?\")\n",
    "radius = int(input(\"How far are you willing to commute in miles?\"))\n",
    "specific_word = input(\"Looking for something specific in this job?\")\n",
    "exempt_word = input(\"Looking to exempt specific words?\")\n",
    "specific_companies = input(\"Any speicific companies you're interested in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = ('https://www.indeed.com/jobs?as_and=Data Scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2450000C000%2B&radius=50&l=Atlanta&fromage=any&limit=10&sort=&psf=advsrch&from=advancedsearch')\n",
    "url = (f'https://www.indeed.com/jobs?as_and={key_word}&as_phr={key_phrase}&as_any={specific_word}&as_not={exempt_word}&as_ttl={specific_word}&as_cmp={specific_companies}&jt=all&st=&salary=%24{salary_in_thousand}2C000%2B&radius={radius}&l={city}&fromage=any&limit=10&sort=&psf=advsrch&from=advancedsearch')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs = driver.find_elements_by_class_name('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_list = []\n",
    "url_list = []\n",
    "pagable = True\n",
    "\n",
    "while pagable == True:\n",
    "    for job in all_jobs:\n",
    "\n",
    "        result_html = job.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(result_html,'html.parser')    \n",
    "\n",
    "        try:\n",
    "            title = soup.find(\"a\",class_=\"jobtitle\").text.replace('\\n','')\n",
    "        except:\n",
    "            title = 'none'\n",
    "        try:\n",
    "            location = soup.find(class_=\"location\").text\n",
    "        except:\n",
    "            location = 'none'             \n",
    "        try:\n",
    "            company = soup.find(class_=\"company\").text.replace('\\n','').strip()\n",
    "        except:\n",
    "            company = 'none'\n",
    "        try:\n",
    "            salary = soup.find(class_='salaryText').text.replace(\"\\n\",\"\").strip()\n",
    "        except:\n",
    "            salary = '$50000+'\n",
    "        try:\n",
    "            post = soup.find('div', class_=\"jobsearch-SerpJobCard unifiedRow row result clickcard\")\n",
    "            url_list.append(f'https://www.indeed.com/viewjob?jk={post[\"data-jk\"]}')\n",
    "        except:\n",
    "            postings = 'none'\n",
    "\n",
    "        sum_div = job.find_elements_by_class_name(\"summary\")[0]\n",
    "\n",
    "        try:\n",
    "            sum_div.click()\n",
    "        except:\n",
    "            close_button = driver.find_elements_by_class_name('popover-x-button-close')\n",
    "            close_button.click()\n",
    "            sum_div.click()\n",
    "\n",
    "        frame = driver.find_element_by_id('vjs-container-iframe')\n",
    "\n",
    "        driver.switch_to.frame(frame)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            html = driver.find_element_by_class_name('jobsearch-jobDescriptionText').get_attribute('innerHTML')\n",
    "        except:\n",
    "            html = 'none'\n",
    "        soup = bs4.BeautifulSoup(html)\n",
    "        job_desc = soup.get_text()\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "        try:\n",
    "            sum_div.click()\n",
    "        except:\n",
    "            close_button.click()\n",
    "            sum_div.click()     \n",
    "        jobs_list.append({\"Title\":title, \"Location\":location,\"Company\":company,\"Salary\":salary,\"Description\":job_desc})\n",
    "    pagable = False\n",
    "    print(f'{len(title)} URLs were found.')\n",
    "    for a in driver.find_elements_by_tag_name('a'):\n",
    "        if 'aria-label=\"Next\"' in a.get_attribute(\"outerHTML\"):\n",
    "            pagable = True\n",
    "            next_button = a\n",
    "            a_soup = bs4.BeautifulSoup(next_button.get_attribute(\"outerHTML\"))\n",
    "            href = a_soup.find('a')['href']\n",
    "            url = \"https://www.indeed.com\" + href\n",
    "            print(\"Moving to next page\")\n",
    "        elif pagable == False:\n",
    "            print(\"No next page found.\")\n",
    "driver.quit()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(jobs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_div = all_jobs[0].find_elements_by_class_name(\"summary\")[0]\n",
    "sum_div.click()\n",
    "driver.find_elements_by_tag_name('iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = driver.find_element_by_id('vjs-container-iframe')\n",
    "\n",
    "driver.switch_to.frame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = driver.find_element_by_class_name('jobsearch-jobDescriptionText').get_attribute('innerHTML')\n",
    "\n",
    "soup = bs4.BeautifulSoup(html)\n",
    "job_desc = soup.get_text()\n",
    "print(job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     job_desc = driver.findElement(By.LocatorStrategy('jobsearch-jobDescriptionText'))\n",
    "    \n",
    "    #df = df.append({\"Title\":title, \"Location\":location,\"Company\":company,\"Description\":job_desc},ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_list = []\n",
    "url_list = []\n",
    "pagable = True\n",
    "\n",
    "while pagable == True:\n",
    "    for job in all_jobs:\n",
    "\n",
    "        result_html = job.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(result_html,'html.parser')    \n",
    "\n",
    "        try:\n",
    "            title = soup.find(\"a\",class_=\"jobtitle\").text.replace('\\n','')\n",
    "        except:\n",
    "            title = 'none'\n",
    "        try:\n",
    "            location = soup.find(class_=\"location\").text\n",
    "        except:\n",
    "            location = 'none'             \n",
    "        try:\n",
    "            company = soup.find(class_=\"company\").text.replace('\\n','').strip()\n",
    "        except:\n",
    "            company = 'none'\n",
    "        try:\n",
    "            salary = soup.find(class_='salaryText').text.replace(\"\\n\",\"\").strip()\n",
    "        except:\n",
    "            salary = '$50000+'\n",
    "        try:\n",
    "            post = soup.find('div', class_=\"jobsearch-SerpJobCard unifiedRow row result clickcard\")\n",
    "            url_list.append(f'https://www.indeed.com/viewjob?jk={post[\"data-jk\"]}')\n",
    "        except:\n",
    "            postings = 'none'\n",
    "\n",
    "        sum_div = job.find_elements_by_class_name(\"summary\")[0]\n",
    "\n",
    "        try:\n",
    "            sum_div.click()\n",
    "        except:\n",
    "            close_button = driver.find_elements_by_class_name('popover-x-button-close')\n",
    "            close_button.click()\n",
    "            sum_div.click()\n",
    "\n",
    "        frame = driver.find_element_by_id('vjs-container-iframe')\n",
    "\n",
    "        driver.switch_to.frame(frame)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            html = driver.find_element_by_class_name('jobsearch-jobDescriptionText').get_attribute('innerHTML')\n",
    "        except:\n",
    "            html = 'none'\n",
    "        soup = bs4.BeautifulSoup(html)\n",
    "        job_desc = soup.get_text()\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "        try:\n",
    "            sum_div.click()\n",
    "        except:\n",
    "            close_button.click()\n",
    "            sum_div.click()     \n",
    "        jobs_list.append({\"Title\":title, \"Location\":location,\"Company\":company,\"Salary\":salary,\"Description\":job_desc})\n",
    "    pagable = False\n",
    "    print(f'{len(title)} URLs were found.')\n",
    "    for a in driver.find_elements_by_tag_name('a'):\n",
    "        if 'aria-label=\"Next\"' in a.get_attribute(\"outerHTML\"):\n",
    "            pagable = True\n",
    "            next_button = a\n",
    "            a_soup = bs4.BeautifulSoup(next_button.get_attribute(\"outerHTML\"))\n",
    "            href = a_soup.find('a')['href']\n",
    "            url = \"https://www.indeed.com\" + href\n",
    "            print(\"Moving to next page\")\n",
    "    if pagable == False:\n",
    "        print(\"No next page found.\")\n",
    "driver.quit()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
